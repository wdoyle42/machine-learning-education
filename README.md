---
output:
  pdf_document: default
  html_document: default
---
# Course Materials for Machine Learning in Education Course

## Will Doyle


Machine learning constitutes a different field from statistics given its focus on 
out-of-sample prediction as opposed to statistics' emphasis on 
inference and estimation. While many of the same algorithms are used,
the purpose of the two are quite distinct. In education, machine learning
supports a variety of predictive tasks, but education researchers are 
rarely trained in the development of machine learning models.

This course will introduce the learner to machine learning in education settings
The focus will be pragrmatic, with an emphasis on how various models
are tuned in order to best provide out-of-sample predictions with the lowest
loss rates. Learners will know how to train and deploy some widely-used models
after taking the course. 

## Evaluation

*Problem Sets* 

There will be 10 problem sets, each of which will be worth 10 points. Assignments 
will constitute 50% of the final grade. 

*Semester-Long Assignment*

Students will create a deployable model trained on an existing dataset. 
Students will write a manuscript describing their process and the nature of the model
(predictive results and variable importance, as appropriate).This manuscript should be 
a good first draft for a manuscript suitable for publication.  Students will also create a 
github repository containing the code to create the model and the deployable model. Students may work either 
alone or in a group of two on this assignment.

There will be four check-in assignments, a draft of the final paper, and the paper. These will be
referred to as "progress reports" draft and final version. 

## Required Texts

James et al, An Introduction to Statistical Learning 

https://www.statlearning.com/

Referred to as *ISLR*

Kuhn and Silge Tidy Modeling with R

https://www.tmwr.org/

Referred to a *TMWR*

## Optional References:

Wickham et al, R for Data Science

https://r4ds.hadley.nz/

Referred to as *R4DS*

Chang, R Graphics Cookbook

https://r-graphics.org/

Referred to as *R Graphics Cookbook*

CS 229 Lecture notes

https://cs229.stanford.edu/main_notes.pdf

https://cs229.stanford.edu/cs229-notes-decision_trees.pdf

Referred to as *CS 229*


## Schedule of Topics

### L1 Regularization, the Lasso 

- Intro to tidymodels

- Feature engineering basics

### Machine Learning Workflow

- Testing and Training

- Validation

- Hyperparameter tuning

- Choosing best fit

- A complete workflow

### L1 and L2 Regularization, Elastic Net

- Understanding hyperparameters

- Measures of model fit: regression and classification

- Tuning approaches: grid search, simulated annealing, genetic algorithms 

### Tree-Based Methods

- Classification and Regression Trees (CART)

- Random Forests

- Understanding hyperparameters in Random Forests

- Fitting and Tuning Parameters

- Prediction from trained models

### Support Vector Machines

- Support Vector Machine Concepts: support vectors, kernel "trick"

- Hyperparameters

- Fitting and Tuning Hyperparameters

- Prediction from trained models

### Neural Networks

- Neural Network Concepts

- Backpropagation

- Activation functions

- Measuring Model fit via cross entropy

- Cross validation and choosing hyperparameters

- Applications


Assignment Due Dates






